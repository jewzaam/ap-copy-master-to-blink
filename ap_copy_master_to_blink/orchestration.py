"""
Main orchestration logic

Generated By: Claude Code (Claude Sonnet 4.5)
"""

from pathlib import Path
from typing import Dict, Optional, Set
import logging

from ap_common.progress import progress_iter, ProgressTracker
from ap_common.constants import (
    NORMALIZED_HEADER_CAMERA,
    NORMALIZED_HEADER_GAIN,
    NORMALIZED_HEADER_EXPOSURESECONDS,
    NORMALIZED_HEADER_FILTER,
    NORMALIZED_HEADER_DATE,
    NORMALIZED_HEADER_FILENAME,
    TYPE_MASTER_DARK,
    TYPE_MASTER_BIAS,
    TYPE_MASTER_FLAT,
)

from .scanning import (
    scan_blink_directories,
    group_lights_by_config,
    sort_groups_by_date,
    collect_filters_by_date,
)
from .path_utils import (
    get_date_directory,
    extract_organization_metrics,
)
from .file_operations import (
    check_masters_exist,
    copy_master_to_blink,
)
from .flat_batch_selection import (
    pre_prompt_flat_selections,
)
from .matching import (
    determine_required_masters,
    find_flat_for_date,
)
from .flat_state import load_state, save_state, update_cutoff
from .statistics import Statistics, create_statistics

logger = logging.getLogger(__name__)

# Set default description width for aligned progress bars
ProgressTracker.set_default_desc_width(20)


def process_blink_directory(
    library_dir: Path,
    blink_dir: Path,
    date_dir_pattern: str,
    *,
    dry_run: bool = False,
    quiet: bool = False,
    scale_darks: bool = False,
    flat_state_path: Optional[Path] = None,
    picker_limit: int = 5,
) -> Statistics:
    """
    Main orchestration logic to copy masters to blink directories.

    Args:
        library_dir: Path to calibration library
        blink_dir: Path to blink directory tree
        date_dir_pattern: Regex pattern to match date directory where masters
                         are copied
        dry_run: If True, log actions but don't copy files (keyword-only)
        quiet: Suppress progress output (keyword-only)
        scale_darks: If False, only exact exposure match darks are copied.
                    If True, shorter exposure darks with bias are allowed.
                    (keyword-only)
        flat_state_path: Path to flat state YAML file. If provided, enables
                        flexible flat date matching with interactive selection.
                        (keyword-only)
        picker_limit: Max older/newer flat dates to show in picker (default: 5,
                     keyword-only)

    Returns:
        Statistics dictionary with summary information
    """
    # Initialize statistics
    stats = create_statistics()

    # Load flat state if enabled
    state: Optional[Dict[str, str]] = None
    if flat_state_path:
        state = load_state(flat_state_path)

    blink_dir_str = str(blink_dir)

    # Scan for light frames
    metadata_list = scan_blink_directories(blink_dir, quiet=quiet)

    if not metadata_list:
        logger.warning("No light frames found to process")
        return stats

    # Extract organizational metrics
    targets, dates, filters = extract_organization_metrics(metadata_list, blink_dir)

    stats["frame_count"] = len(metadata_list)
    stats["target_count"] = len(targets)
    stats["date_count"] = len(dates)
    stats["filter_count"] = len(filters)

    # Group by calibration configuration
    groups = group_lights_by_config(metadata_list)
    stats["configs_processed"] = len(groups)

    # Collect filters needed per date (for batch prompting)
    filters_by_date = collect_filters_by_date(groups)

    # Cache for flat date selections: {light_date → selected_flat_date}
    flat_selections: Dict[str, Optional[str]] = {}

    # Collect warnings to print after progress bar
    warnings = []

    # Track which DATE directories we've processed to avoid duplicate copies
    processed_masters: Dict[Path, Set[str]] = {}

    # Sort groups by date when flexible flat matching is enabled.
    # Critical: oldest-first ordering ensures state file updates cascade
    # correctly—choices for earlier dates inform what's valid for later dates.
    if state is not None:
        sorted_groups = sort_groups_by_date(groups)
    else:
        sorted_groups = list(groups.items())

    # Pre-prompt for flat dates when flexible matching enabled
    # This prompts ONCE per date (not per filter) for better UX
    if state is not None:
        flat_selections = pre_prompt_flat_selections(
            library_dir,
            groups,
            filters_by_date,
            blink_dir_str,
            state,
            quiet,
            scale_darks,
            picker_limit,
        )

    # Process each unique configuration
    for config_key, lights in progress_iter(
        sorted_groups,
        desc="Processing configurations",
        unit="configs",
        enabled=not quiet,
        total=len(sorted_groups),
    ):
        # Use first light's metadata as representative for this group
        light_metadata = lights[0]

        logger.debug(
            f"Processing: "
            f"camera={light_metadata.get(NORMALIZED_HEADER_CAMERA)}, "
            f"gain={light_metadata.get(NORMALIZED_HEADER_GAIN)}, "
            f"exposure={light_metadata.get(NORMALIZED_HEADER_EXPOSURESECONDS)}s, "
            f"filter={light_metadata.get(NORMALIZED_HEADER_FILTER)}, "
            f"date={light_metadata.get(NORMALIZED_HEADER_DATE)}"
        )

        # Find required masters
        masters = determine_required_masters(
            library_dir, light_metadata, scale_darks=scale_darks
        )
        dark = masters[TYPE_MASTER_DARK]
        bias = masters[TYPE_MASTER_BIAS]
        flat = masters[TYPE_MASTER_FLAT]

        light_date = light_metadata.get(NORMALIZED_HEADER_DATE, "")
        filter_name = light_metadata.get(NORMALIZED_HEADER_FILTER, "")

        # Flexible flat matching: use cached selection if no exact flat
        if flat is None and state is not None and light_date in flat_selections:
            # Use pre-selected flat date for this light date
            selected_date = flat_selections[light_date]
            if selected_date:
                flat = find_flat_for_date(library_dir, light_metadata, selected_date)
                if not flat:
                    logger.error(
                        f"BUG: Selected date {selected_date} missing flat for "
                        f"filter {filter_name} on {light_date} (should not happen)"
                    )
        elif flat is not None and state is not None:
            # Exact match found: advance cutoff to this date
            if light_date:
                update_cutoff(state, blink_dir_str, light_date)

        # Get all unique DATE directories in this group
        # (lights from multiple targets may share the same calibration config)
        date_dirs = set()
        for light in lights:
            lights_dir = Path(light[NORMALIZED_HEADER_FILENAME]).parent
            date_dir = get_date_directory(lights_dir, date_dir_pattern)
            date_dirs.add(date_dir)

        # Track whether any date_dir has the required masters
        any_dark_present = False
        any_flat_present = False

        # Copy masters to each DATE directory
        for date_dir in date_dirs:
            # Ensure we have a tracking set for this DATE directory
            if date_dir not in processed_masters:
                processed_masters[date_dir] = set()

            # Check if the specific masters we need already exist in date_dir
            existing_masters = check_masters_exist(date_dir, dark, bias, flat)

            # Copy dark (if needed and not already present)
            stats["darks_needed"] += 1
            if existing_masters["has_dark"]:
                logger.debug("Dark already exists in blink for this configuration")
                stats["darks_present"] += 1
                any_dark_present = True
            elif dark:
                dark_name = Path(dark[NORMALIZED_HEADER_FILENAME]).name
                if dark_name not in processed_masters[date_dir]:
                    copy_master_to_blink(dark, date_dir, dry_run)
                    processed_masters[date_dir].add(dark_name)
                stats["darks_present"] += 1
                any_dark_present = True

            # Copy bias (if needed and not already present)
            if bias:
                stats["biases_needed"] += 1
                if existing_masters["has_bias"]:
                    logger.debug("Bias already exists in blink for this configuration")
                    stats["biases_present"] += 1
                else:
                    bias_name = Path(bias[NORMALIZED_HEADER_FILENAME]).name
                    if bias_name not in processed_masters[date_dir]:
                        copy_master_to_blink(bias, date_dir, dry_run)
                        processed_masters[date_dir].add(bias_name)
                    stats["biases_present"] += 1

            # Copy flat (if needed and not already present)
            stats["flats_needed"] += 1
            if existing_masters["has_flat"]:
                logger.debug("Flat already exists in blink for this configuration")
                stats["flats_present"] += 1
                any_flat_present = True
            elif flat:
                flat_name = Path(flat[NORMALIZED_HEADER_FILENAME]).name
                if flat_name not in processed_masters[date_dir]:
                    copy_master_to_blink(flat, date_dir, dry_run)
                    processed_masters[date_dir].add(flat_name)
                stats["flats_present"] += 1
                any_flat_present = True

        # Collect missing master warnings (print after progress bar)
        # Only warn if not found in library AND not already present in any date_dir
        if not dark and not any_dark_present:
            exp = light_metadata.get(NORMALIZED_HEADER_EXPOSURESECONDS)
            warnings.append(
                f"Missing dark for exposure={exp}s "
                f"(run with --debug for search details)"
            )

        if not flat and not any_flat_present:
            filt = light_metadata.get(NORMALIZED_HEADER_FILTER)
            date = light_metadata.get(NORMALIZED_HEADER_DATE)
            warnings.append(
                f"Missing flat for filter={filt}, "
                f"date={date} "
                f"(run with --debug for search details)"
            )

    # Print collected warnings after progress bar completes
    for warning in warnings:
        logger.warning(warning)

    # Save state file (unless dry_run)
    if state is not None and flat_state_path:
        if dry_run:
            logger.debug("Dry run: state file not saved")
        else:
            save_state(flat_state_path, state)

    return stats
